0.04NovaBank: Proactive Retention — Executive Summary 
========================================================================================

The problem
-----------
Margins are being squeezed while customer churn continues to erode profitability. Today we mostly react after customers leave. We need to spot likely churners early and focus our limited outreach on people where a contact and a tailored offer will actually pay off.

What we built
-------------
A practical, end-to-end decision system that:
- Scores every customer for their chance to say “yes” to a save offer.
- Chooses who to contact to maximize euros, not just model accuracy—either (a) the profit-max cutoff or (b) the top‑K customers if operations have a contact capacity.
- Explains the “why” behind each decision with simple reason codes so front‑line teams and Risk/Compliance can see the key drivers for each customer.

What we ran and why
-------------------
We compared several approaches on a held‑out test set with the same split and money assumptions. We included options that balance performance and trust:
- XGBoost (XGB) — strong pattern‑finding with support for profit‑weighted training and calibration.
- Gradient Boosting (GB, sklearn) — solid boosted trees benchmark.
- Pruned Decision Tree (DT) — slightly behind the boosters on profit but very easy to explain.
- Logistic Regression — well‑calibrated baseline.
- Baselines: “Do nothing” and a simple rule (“contact if prior campaign was a success”).

Money assumptions used in the analysis (and adjustable in the code): €20 cost per contact, €250 value if an at‑risk customer accepts the offer.

Final results (profit‑max thresholds)
------------------------------------
- XGBoost — Winner
  - Net profit: €97,530
  - Cutoff (threshold): 0.04 (contact anyone with ≥ 4% chance to say yes)
  - Targeted: 7,536 customers
  - Hit rate (precision): 14.3% (~1 in 6 contacted said yes)
  - Coverage (recall): 92.8% (captured over 9 out of 10 yeses)
  - Added vs Do‑Nothing: €118,280
  - Counts: TP 1,076, FP 6,460, FN 83, TN 2,674
- Pruned Decision Tree: €95,550 (threshold 0.045; precision 14.4%; recall 92.1%)
- Gradient Boosting: €94,230 (threshold 0.040; precision 13.1%; recall 95.3%)
- Logistic Regression: €92,750 (threshold 0.035; precision 12.8%; recall 96.0%)
- Simple Rule (“prior success”): –€188,050 net
- Do‑Nothing: –€289,750 net

Why the 0.04 cutoff makes sense (plain language)
-------------------------------------------------
Every customer gets a “chance to say yes” score. We contact anyone at 4% or higher. That may look low, but calling costs €20 while a saved customer is worth €250. If we set the bar higher, we miss too many saves; at 4% we still make some calls that don’t convert, but overall we keep many more customers, which maximizes total profit under today’s economics. (If costs or values change, the best cutoff moves—our scripts re‑find it quickly.)

Our recommendation (what to do)
-------------------------------
1. Adopt XGBoost as the primary model, using the 0.04 profit‑max cutoff from this run.  
   - If operations are capacity‑constrained, select the top‑K customers by XGB score instead of a fixed cutoff.
2. Keep the Pruned Decision Tree as a transparency companion—its clear, flow‑chart‑like rules make decisions easy to audit and explain.  
3. Ship customer‑level reason codes so agents know why each customer was selected and what to emphasize in conversations.

Why this works (rationale)
--------------------------
- It optimizes euros, not just model accuracy—balancing wasted offers (false positives) against missed saves (false negatives).
- Profit‑weighted training and optional calibration align learning and cutoffs to your actual economics.
- It’s operationally flexible: the same scores support a profit‑max cutoff or capacity‑based top‑K targeting.

Expected impact
---------------
- More net profit from retention (XGB delivered the best € in our runs).  
- Better agent productivity (calling the right customers, with clear talking points).  
- Faster learning loops (threshold sweeps show where profit turns negative; calibration plots show whether probabilities are trustworthy).

Pilot plan (4–6 weeks)
----------------------
- Scope: A/B test the new policy against current practice on a representative slice.  
- KPIs: Net € uplift, hit rate (precision), coverage (recall), opt‑outs/complaints.  
- Playbook: Start with the 0.04 cutoff; if capacity‑limited, use top‑K. Share plain‑language reason codes with agents.

Key risks & safeguards
----------------------
1. Economics can shift (offer cost/value) → the optimal cutoff changes.  
   - *Safeguard:* Re‑run the threshold sweep monthly; adjust as needed.  
2. Contact fatigue / CX if we call too many low‑probability customers.  
   - *Safeguard:* Contact caps and suppression rules; monitor precision and opt‑outs.  
3. Fairness & compliance (some drivers may correlate with sensitive factors).  
   - *Safeguard:* Keep the pruned tree and reason codes for transparency; run periodic fairness checks and document exclusions.

Bottom line
-----------
Adopt XGBoost with a 0.04 cutoff (or top‑K when capped). It targets the right customers, keeps more revenue, and gives agents clear, defensible reasons to guide each conversation.
